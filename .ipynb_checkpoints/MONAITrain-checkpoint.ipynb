{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7a8dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygments==2.14.0 in /Users/jonty/opt/anaconda3/lib/python3.9/site-packages (2.14.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pygments==2.14.0\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from MONAICardiacDataset import MONAICardiacDataset\n",
    "from MONAIModel import UNet\n",
    "import monai\n",
    "from monai.losses import DiceLoss as diceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70762ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.Affine(scale=(0.85, 1.15),\n",
    "              rotate=(-45, 45)),\n",
    "    iaa.ElasticTransformation()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7800f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1911 train images and 360 val images\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset objects\n",
    "train_path = Path(\"Preprocessed/train/\")\n",
    "val_path = Path(\"Preprocessed/val\")\n",
    "\n",
    "train_dataset = MONAICardiacDataset(train_path, seq)\n",
    "val_dataset = MONAICardiacDataset(val_path, None)\n",
    "\n",
    "print(f\"There are {len(train_dataset)} train images and {len(val_dataset)} val images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e604fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce242580",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtriumSegmentation(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = UNet()\n",
    "        \n",
    "        self.optimizer = monai.optimizers.Novograd(self.model.parameters(), lr=1e-4)\n",
    "        self.loss_fn = monai.losses.DiceLoss()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return torch.sigmoid(self.model(data))\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        mri, mask = batch\n",
    "        mask = mask.float()\n",
    "        pred = self(mri)\n",
    "        loss = self.loss_fn(pred, mask)\n",
    "#         hausdorff = monai.metrics.compute_hausdorff_distance(pred, mask)\n",
    "#         prec = monai.metrics.compute_confusion_matrix_metric(\n",
    "#             metric_name=\"precision\",\n",
    "#             confusion_matrix=monai.metrics.get_confusion_matrix(pred, mask)\n",
    "#         )\n",
    "#         rec = monai.metrics.compute_confusion_matrix_metric(\n",
    "#             metric_name=\"recall\",\n",
    "#             confusion_matrix=monai.metrics.get_confusion_matrix(pred, mask)\n",
    "#         )\n",
    "        \n",
    "        self.log(\"Train Dice\", loss)\n",
    "#         self.log(\"Train Hausdorff Distance\", hausdorff.mean())\n",
    "#         self.log(\"Train Precision\", prec.mean())\n",
    "#         self.log(\"Train Recall\", rec.mean())\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            self.log_images(mri.cpu(), pred.cpu(), mask.cpu(), \"Train\")\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        mri, mask = batch\n",
    "        mask = mask.float()\n",
    "        pred = self(mri)\n",
    "        loss = self.loss_fn(pred, mask)\n",
    "#         hausdorff = monai.metrics.compute_hausdorff_distance(pred, mask)\n",
    "#         prec = monai.metrics.compute_confusion_matrix_metric(\n",
    "#             metric_name=\"precision\",\n",
    "#             confusion_matrix=monai.metrics.get_confusion_matrix(pred, mask)\n",
    "#         )\n",
    "#         rec = monai.metrics.compute_confusion_matrix_metric(\n",
    "#             metric_name=\"recall\",\n",
    "#             confusion_matrix=monai.metrics.get_confusion_matrix(pred, mask)\n",
    "#         )\n",
    "        \n",
    "        self.log(\"Val Dice\", loss)\n",
    "#         self.log(\"Val Hausdorff Distance\", hausdorff.mean())\n",
    "#         self.log(\"Val Precision\", prec.mean())\n",
    "#         self.log(\"Val Recall\", rec.mean())\n",
    "        \n",
    "        if batch_idx % 2 == 0:\n",
    "            self.log_images(mri.cpu(), pred.cpu(), mask.cpu(), \"Val\")\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def log_images(self, mri, pred, mask, name):\n",
    "        \n",
    "        pred = pred > 0.5\n",
    "        \n",
    "        fig, axis = plt.subplots(1, 2)\n",
    "        axis[0].imshow(mri[0][0], cmap=\"bone\")\n",
    "        mask_ = np.ma.masked_where(mask[0][0]==0, mask[0][0])\n",
    "        axis[0].imshow(mask_, alpha=0.6)\n",
    "        \n",
    "        axis[1].imshow(mri[0][0], cmap=\"bone\")\n",
    "        mask_ = np.ma.masked_where(pred[0][0]==0, pred[0][0])\n",
    "        axis[1].imshow(mask_, alpha=0.6)\n",
    "        \n",
    "        self.logger.experiment.add_figure(name, fig, self.global_step)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return [self.optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2259b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "model = AtriumSegmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bf1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='Val Dice',\n",
    "    save_top_k=10,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c97019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonty/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:474: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, logger=TensorBoardLogger(save_dir='logs'), log_every_n_steps=1,\n",
    "                    callbacks=checkpoint_callback, max_epochs=75, accelerator='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7cb341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type     | Params\n",
      "-------------------------------------\n",
      "0 | model   | UNet     | 7.8 M \n",
      "1 | loss_fn | DiceLoss | 0     \n",
      "-------------------------------------\n",
      "7.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.8 M     Total params\n",
      "31.127    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf6b9352e6e4cef8fc3bfd38491e7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6626dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from tqdm.notebook import tqdm\n",
    "from celluloid import Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e4fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AtriumSegmentation.load_from_checkpoint(\"weights/70.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval();\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "for slice, label in tqdm(val_dataset):\n",
    "    slice = torch.tensor(slice).to(device).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        pred = model(slice)\n",
    "    preds.append(pred.cpu().numpy())\n",
    "    labels.append(label)\n",
    "    \n",
    "preds = np.array(preds)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f712eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-model.loss_fn(torch.from_numpy(preds), torch.from_numpy(labels))  # two possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe234d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_score = 1-monai.losses.DiceLoss()(torch.from_numpy(preds), torch.from_numpy(labels).unsqueeze(0).float())\n",
    "print(f\"The Val Dice Score is: {dice_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373659dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = Path(\"Data/imagesTs/la_002.nii.gz\")\n",
    "subject_mri = nib.load(subject).get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed4c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for normalization and standardization\n",
    "def normalize(full_volume):\n",
    "    \"\"\"\n",
    "    Z-Normalization of the whole subject\n",
    "    \"\"\"\n",
    "    mu = full_volume.mean()\n",
    "    std = np.std(full_volume)\n",
    "    normalized = (full_volume - mu) / std\n",
    "    return normalized\n",
    "\n",
    "def standardize(normalized_data):\n",
    "    \"\"\"\n",
    "    Standardize the normalized data into the 0-1 range\n",
    "    \"\"\"\n",
    "    standardized_data = (normalized_data - normalized_data.min()) / (normalized_data.max() - normalized_data.min())\n",
    "    return standardized_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8f83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_mri = subject_mri[32:-32, 32:-32]\n",
    "standardized_scan = standardize(normalize(subject_mri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44821f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_scan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(standardized_scan.shape[-1]):\n",
    "    slice = standardized_scan[:,:,i]\n",
    "    with torch.no_grad():\n",
    "        pred = model(torch.tensor(slice).unsqueeze(0).unsqueeze(0).float().to(device))[0][0]\n",
    "        pred = pred > 0.5\n",
    "    preds.append(pred.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c038545",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "camera = Camera(fig)  # create the camera object from celluloid\n",
    "\n",
    "for i in range(standardized_scan.shape[-1]):\n",
    "    plt.imshow(standardized_scan[:,:,i], cmap=\"bone\")\n",
    "    mask = np.ma.masked_where(preds[i]==0, preds[i])\n",
    "    plt.imshow(mask, alpha=0.5, cmap=\"autumn\")\n",
    "    \n",
    "    camera.snap()  # Store the current slice\n",
    "animation = camera.animate()  # create the animation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(animation.to_html5_video())  # convert the animation to a video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
